{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f65c11e-5635-4449-80f4-2d473f10062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa99ae9-d665-487b-a998-10dae159a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfc9965-d66a-472d-ab53-01e0b36def22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional,List\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from recs.dataset import session_parallel_dataset\n",
    "from recs.evaluator import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3412c4-130e-4399-af0e-f9103102ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(tfk.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items:int,\n",
    "        seq_len:Optional[int]=3,\n",
    "        hidden_dim:Optional[int]=100,\n",
    "        embed_dim:Optional[int]=100,\n",
    "        dropout_rate:Optional[int]=0.5,\n",
    "        name=\"QNet\"\n",
    "    ):\n",
    "        super(QNet, self).__init__(name=name)\n",
    "        \n",
    "        self._embedding = tfk.layers.Embedding(num_items, embed_dim, mask_zero=True)\n",
    "        self._gru = tfk.layers.GRU(\n",
    "            hidden_dim, \n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self._qvalue_dense = tfk.layers.Dense(num_items+1, activation=None) # アイテム数 + 状態の価値を定義\n",
    "        self._lambda = tfk.layers.Lambda(\n",
    "            lambda x: tf.expand_dims(x[:, 0], axis=-1) + x[:, 1:] - tf.reduce_mean(x[:, 1:], axis=-1, keepdims=True),\n",
    "            output_shape=(num_items, )\n",
    "        )\n",
    "    \n",
    "    def call(\n",
    "        self, \n",
    "        item_seqs:tf.Tensor, # (batch_size, seq_len)\n",
    "        training:Optional[bool]=False,\n",
    "    ):\n",
    "        x = self._embedding(item_seqs)\n",
    "        x = self._gru(x, training=training)\n",
    "        x = self._qvalue_dense(x)\n",
    "        qvalue = self._lambda(x)\n",
    "        return qvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4c0493-8bb9-4993-b8dd-15c4505cae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNRec(tfk.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_items:int,\n",
    "        seq_len:Optional[int]=3,\n",
    "        hidden_dim:Optional[int]=100,\n",
    "        embed_dim:Optional[int]=100,\n",
    "        dropout_rate:Optional[int]=0.5,\n",
    "        gamma:Optional[float]=1.,\n",
    "        tau:Optional[float]=1.,\n",
    "        update_freq:Optional[int]=100,\n",
    "        name=\"DQNRec\"\n",
    "    ):\n",
    "        super(DQNRec, self).__init__(name=name)\n",
    "        \n",
    "        self._num_items = num_items\n",
    "        self._tau = tau\n",
    "        self._gamma = gamma\n",
    "        self._update_freq = update_freq\n",
    "        self._update_count = 0\n",
    "        \n",
    "        self._model = QNet(\n",
    "            num_items,seq_len,hidden_dim,embed_dim, dropout_rate)\n",
    "        self._target_model = QNet(\n",
    "            num_items,seq_len,hidden_dim,embed_dim, dropout_rate)\n",
    "        \n",
    "        self._loss_tracker = tfk.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "        dummy_state = tf.zeros((1, seq_len), dtype=tf.int32)\n",
    "        self._model(dummy_state)\n",
    "        self._target_model(dummy_state)\n",
    "    \n",
    "    def soft_update(self):\n",
    "        for param, target_param in zip(self._model.trainable_variables, self._target_model.trainable_variables):\n",
    "            target_param.assign(param*self._tau + target_param*(1-self._tau))\n",
    "    \n",
    "    def call(self, states, training:Optional[bool]=False):\n",
    "        return self._model(states, training)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        state, action, reward, n_state, done = data\n",
    "        onehot_act = tf.one_hot(action-1, depth=self._num_items)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            qvalue = self._model(state, training=True)\n",
    "            n_qvalue = self._model(n_state, training=True)\n",
    "            n_qvalue_ = self._target_model(n_state, training=True)\n",
    "            \n",
    "            greedy_a = tf.argmax(n_qvalue, axis=-1)\n",
    "            onehot_greedy_a = tf.one_hot(greedy_a, depth=self._num_items)\n",
    "            \n",
    "            target = reward + (1.0 - done) * self._gamma * tf.reduce_sum(n_qvalue_*onehot_greedy_a, axis=-1)\n",
    "            target = tf.stop_gradient(target)\n",
    "            loss = self.loss(target, tf.reduce_sum(qvalue*onehot_act,axis=-1))\n",
    "            \n",
    "        grads = tape.gradient(loss, self._model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self._model.trainable_variables))\n",
    "        self._loss_tracker.update_state(loss)\n",
    "        \n",
    "        self._update_count += 1\n",
    "        if self._update_count % self._update_freq == 0:\n",
    "            self.soft_update()\n",
    "        \n",
    "        return  {\"loss\": self._loss_tracker.result()}\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self._loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350dfac8-f94e-4431-b591-94cd88f47c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname=\"diginetica\"\n",
    "modelname = \"DQNRec\"\n",
    "default_logdir = \"/home/inoue/work/recs/\"\n",
    "log_dir =  os.path.join(default_logdir, \"logs/%s/%s/\"%(dataname, modelname)+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "train = pickle.load(open(\n",
    "    \"/home/inoue/work/dataset/%s/derived/mdp_train.df\"%dataname, \"rb\"\n",
    "))\n",
    "data = pd.read_pickle(\"~/work/dataset/%s/derived/train.df\"%dataname)\n",
    "testdata = pd.read_pickle(\"~/work/dataset/%s/derived/test.df\"%dataname)\n",
    "\n",
    "num_items = max(data.itemId.max(), testdata.itemId.max())+1\n",
    "emb_dim = 64\n",
    "hidden_dim = 64\n",
    "seq_len = train[1].shape[1]\n",
    "batch_size=500\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train[1],train[2],train[3],train[4], train[5].astype(np.float32))\n",
    ").shuffle(len(train[0])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec3d6e2-dc7c-4fa4-ae73-9d6409e2f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQNRec(num_items, seq_len, hidden_dim, emb_dim, dropout_rate=0.1, gamma=1., update_freq=718)\n",
    "model.compile(loss=tfk.losses.Huber(), optimizer=tfk.optimizers.Adam(learning_rate=0.01))\n",
    "model.build(input_shape=(1,seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8072d0-cc48-4620-b3f4-89246307e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "718/718 [==============================] - 55s 64ms/step - loss: 0.0103\n",
      "Epoch 2/20\n",
      "718/718 [==============================] - 47s 64ms/step - loss: 4.0668e-04\n",
      "Epoch 3/20\n",
      "718/718 [==============================] - 46s 62ms/step - loss: 0.0011\n",
      "Epoch 4/20\n",
      "718/718 [==============================] - 46s 62ms/step - loss: 0.0012\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb08817d280>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data, \n",
    "    epochs=20, \n",
    "    callbacks=[\n",
    "        tfk.callbacks.TensorBoard(log_dir=log_dir), \n",
    "        tfk.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(default_logdir, \"params/%s/%s/checkpoint\"%(dataname, modelname)),\n",
    "            save_weights_only=True,\n",
    "            monitor=\"loss\",\n",
    "            mode=\"min\",\n",
    "            save_best_only=True\n",
    "        ),\n",
    "        tfk.callbacks.EarlyStopping(\n",
    "            monitor=\"loss\",\n",
    "            min_delta=1e-4,\n",
    "            patience=2,\n",
    "            mode=\"min\",\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d60864-210d-4fe0-b6e8-3b26cf13de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pickle.load(open(\n",
    "    \"/home/inoue/work/dataset/%s/derived/mdp_test.df\"%dataname, \"rb\"))\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test[0],test[1],test[2])).shuffle(len(test[0])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1375930-3ae0-466a-bb3d-ed464e5679a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb0a62411af43da94ec4a441df84a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k =20\n",
    "df = pd.DataFrame(columns=[\"sessionId\", \"recIds\", \"choiceId\"])\n",
    "for batch in tqdm(test_data):\n",
    "    sess, state, target = batch\n",
    "    pred_score = model(state)\n",
    "    topkitem = tf.math.top_k(pred_score, k=k)[1].numpy() + 1\n",
    "    tmp = pd.DataFrame(\n",
    "        [sess.numpy(), topkitem, target.numpy()]).T\n",
    "    tmp.columns = [\"sessionId\", \"recIds\", \"choiceId\"]\n",
    "    df = pd.concat([df, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7414fcd-5b38-4e87-87d0-7ca0dc612f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k_ in [5, 10, 15, 20]:\n",
    "    df[\"NDCG@%d\"%k_] = df[[\"recIds\", \"choiceId\"]].apply(lambda x: metrics.ndcg_at_k(x[1], x[0], k=k_), axis=1)\n",
    "    df[\"Hit@%d\"%k_] = df[[\"recIds\", \"choiceId\"]].apply(lambda x: metrics.hit_at_k(x[1], x[0], k=k_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7956ca6-fe58-4b81-8853-78d7cc6964b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDCG@5     0.000119\n",
       "Hit@5      0.000138\n",
       "NDCG@10    0.000201\n",
       "Hit@10     0.000322\n",
       "NDCG@15    0.000227\n",
       "Hit@15     0.000391\n",
       "NDCG@20    0.000282\n",
       "Hit@20     0.000551\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"sessionId\").sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38a9e1-ae9b-4460-af05-859f4e7d4c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
